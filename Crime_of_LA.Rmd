---
title: "STAT847project Crime Analysis of Los Angeles"
author: "Zhenyu Tan 20697649"
date: "2018/3/19"
output:
  html_document:
    df_print: paged
  pdf_document:
    keep_tex: yes
---


Los Angeles is one of the largest cities in American with huge amount of population.Crime, as one of the important topics for all the huge cities, is also gained attention from the public in Los Angeles.This project will focus on this social-concerned issue and get some insights of it. There are mainly four sections in this paper:Crime Overview, Victim Analysis,Criminal Activities Analysis and Comparison with Crimes in Vancouver.
The detailed analysis is shown as below.


#Data Preprocessing

```{r}
library(plotly)
library(magrittr)
library(dplyr)
if (!require('devtools')) install.packages('devtools')
devtools::install_github('rstudio/leaflet')

crime_data=read.csv('/Users/tanzhenyu/Desktop/Stat847/Crime_Data_from_2010_to_Present.csv',header = T)
dim(crime_data)# dimension of the data

crime_cleaned=crime_data[,-c(1,5,6,7,8,14,16,18,20,21,22,23,25)]#delete the columns that are not important with too many missing values or is the code representation of the description part 

```

Check if there are any missing values in the time features.

```{r}
sprintf('There are %i missing values in Time.Occurred',sum(is.na(crime_cleaned$Time.Occurred))+ sum(crime_cleaned$Time.Occurred==' '))

sprintf('There are %i missing values in Date.Occurred',sum(is.na(crime_cleaned$Date.Occurred))+ sum(crime_cleaned$Date.Occurred==' '))

sprintf('There are %i missing values in Date.Reported',sum(is.na(crime_cleaned$Date.Reported))+ sum(crime_cleaned$Date.Reported==' '))
```


As shwon, there are no missing values in time features, thus here the crime hour,month, year subtraction will be done using all data.

```{r}
crime_hour=rep(0,nrow(crime_cleaned))
for(i in 1:nrow(crime_cleaned))
{
  if(crime_cleaned$Time.Occurred[i]>999)
  {crime_hour[i]=as.numeric(substr(as.character(crime_cleaned$Time.Occurred[i]),1,2))
  }else{
  crime_hour[i]=as.numeric(substr(as.character(crime_cleaned$Time.Occurred[i]),1,1))
  }
}

year=format(as.Date(as.character(crime_cleaned$Date.Occurred),format='%m/%d/%Y'),'%Y')
month=format(as.Date(as.character(crime_cleaned$Date.Occurred),format='%m/%d/%Y'),'%m')

Time_occurred=as.Date(as.character(crime_cleaned$Date.Occurred),format='%m/%d/%Y')
Time_reported=as.Date(as.character(crime_cleaned$Date.Reported),format='%m/%d/%Y')
Delayed_time=difftime(Time_reported,Time_occurred, units="days")

crime_final=crime_cleaned%>%mutate(crime_hour=crime_hour,year=as.numeric(year),month=as.numeric(month),Delayed_time=Delayed_time)

names(crime_final)=c("Date_Reported","Date_Occurred","Time_Occurred",                "CrimeCode_Description","MO_Codes","Victim_Age",            "Victim_Sex","Victim_Descent","Premise_Description","Weapon_Description",     "Status_Description","Address","Location",'crime_hour','year','month','Delayed_time')

```



#Crime Overview

Since here it is improper to simply delete all the rows with NA values as it might influence the distribution of crimes, especially the number of crime each year largely. Carefully detection of the number of NA values deleted each year has to to implemented.

Thus, let's first test if there are some missing values in the crime description column which is used in this section.

```{r}
sprintf('There are %i missing values',sum(is.na(crime_final$CrimeCode_Description))+sum(crime_final$CrimeCode_Description==''))
```

As shown there are 398 missing values here in the crime description part, since the volume of missing values is not large,indicating that the analysis on the number and category of crimes can be done using all data.


##Top 5 crimes 


Let's first starts with some interesting facts,what are the top 5 crimes in Los Angeles, this analysis is based on all data from 2010.Jan~2018.Feb.

```{r}
#plot setting
xaxis <- list(title = "",
             showline = TRUE,
             showgrid = FALSE,
             showticklabels = TRUE,
             linecolor = 'rgb(204, 204, 204)',
             linewidth = 2,
             autotick = FALSE,
             ticks = 'outside',
             tickcolor = 'rgb(204, 204, 204)',
             tickwidth = 3,
             ticklen = 6,
             tickfont = list(family = 'Arial',
                             size = 12,
                             color = 'rgb(82, 82, 82)'))
yaxis <- list(title = "",
             showgrid = T,
             zeroline = FALSE,
             showline = T,
             showticklabels = T)
margin <- list(autoexpand = T,
              l = 90,
              r = 90,
              t = 110)

top_5=crime_final%>%
            transmute(crime=CrimeCode_Description)%>%
            count(crime)%>%
            arrange(desc(n))%>%
            top_n(5)
top_5_crime=top_5$crime


sprintf('The top 5 crimes include %s',top_5_crime)
 
```
As shown, the top 5 crimes during 2010.Jan~2018.Feb are **BATTERY - SIMPLE ASSAULT**,**BURGLARY FROM VEHICLE**,**VEHICLE - STOLEN**,**BURGLARY**,**THEFT PLAIN - PETTY ($950 & UNDER)**.


##Crime v.s Year

Firstly, let's get some general idea of number of crimes happened in Los Angeles from 2010 to 2017.


```{r}

crime_2010_2017=lapply(c(2010,2011,2012,2013,2014,2015,2016,2017),FUN=function(i){crime_final[crime_final$year==i,]})

Y=c(2010,2011,2012,2013,2014,2015,2016,2017)

V_num=c(dim(crime_2010_2017[[1]])[1],dim(crime_2010_2017[[2]])[1],dim(crime_2010_2017[[3]])[1],dim(crime_2010_2017[[4]])[1],dim(crime_2010_2017[[5]])[1],dim(crime_2010_2017[[6]])[1],dim(crime_2010_2017[[7]])[1],dim(crime_2010_2017[[8]])[1])

Victim.df=data.frame(t(rbind(Y,V_num)))




plot_ly(Victim.df, x = ~Y, y = ~V_num, type = 'scatter', mode = 'lines+markers')%>%layout(title = "Crime Number Change", xaxis = xaxis, yaxis = yaxis, margin = margin,autosize = FALSE,showlegend = F) 

```

As shown, 2013 is the bottom of the whole plot and then after 2013,the crime tends to increase till 2017.As searched, the reasons for this weird change is that the classify procedure was tightened.Before 2013, as critisized,the LAPD significantly understated the city's true level of crime by its loose procedure of classifying crimes. The bulk of errors were made when police officer recorded the assaults as minor incidents which are not included in this data set.Besides,there are also voices that this increase might result from the increment of the homeless and increasing unemployment rate for people in the bottom class.



Then, let's explore the change in violent crimes and in property crimes, the classification of these two types are following the common one in criminology.

###Violent Crime

```{r}
violent_try=unique(crime_final$CrimeCode_Description)[grepl(pattern=c('ROBBERY|HOMICIDE|RAPE|AGGRAVATED ASSAULT'),unique(crime_final$CrimeCode_Description))]#Firstly, we try to subtract the crimes containing these words, crimes with these words are categorized as violent crimes if it is not an attempt one.
print(violent_try)
```
```{r}
violent_type=violent_try[c(1,2,4,5,6,8)]#exclude those attempted ones
```


```{r}
crime_2010_2017_violent=lapply(c(1:8),
    FUN=function(i){crime_2010_2017[[i]]%>%
    filter(CrimeCode_Description%in%violent_type)%>%
    group_by(CrimeCode_Description)%>%
    count()
})

type_violent=sapply(c(1:length(violent_type)),FUN = function(i)
{sapply(c(1:8),FUN=function(j){crime_2010_2017_violent[[j]][crime_2010_2017_violent[[j]]$CrimeCode_Description==violent_type[i],2]})})


crime_type.df=data.frame(matrix(unlist(cbind(Y,type_violent)),nrow=8,ncol=(length(violent_type)+1)))
colnames(crime_type.df)=c('year','n1','n2','n3','n4','n5','n6')

crime_type.df%>%plot_ly(x = ~year, y = ~n1, type = 'scatter', mode = 'lines+markers',name=paste(violent_type[1]))%>%
add_trace(y = ~n2, type = 'scatter', mode = 'lines+markers',name=paste(violent_type[2]))%>%
add_trace(y = ~n3, type = 'scatter', mode = 'lines+markers',name=paste(violent_type[3]))%>%
add_trace(y = ~n4, type = 'scatter', mode = 'lines+markers',name=paste(violent_type[4]))%>%
add_trace(y = ~n5, type = 'scatter', mode = 'lines+markers',name=paste(violent_type[5]))%>%
add_trace(y = ~n6, type = 'scatter', mode = 'lines+markers',name=paste(violent_type[6]))%>%
layout(title = "Violent Crime changes", xaxis = xaxis, yaxis = yaxis,autosize = T,legend=list(x = 1, y = 0.4,font = list(size=10) ))


```

As shown, for violent crimes, aggravated assault with deadly weapon and aggravated assault between intimate partners increase a lot after 2013 which are the dominant effects here influencing the increase after 2013.




###Property Crime

```{r}
property_try=unique(crime_final$CrimeCode_Description)[grepl(pattern=c('BURGLARY|THEFT'),unique(crime_final$CrimeCode_Description))]#Firstly, we try to subtract the crimes containing these words, crimes with these words are categorized as violent crimes if it is not an attempt one.
print(property_try)
```
```{r}
Moto_theft_type=property_try[grepl(pattern=c('VEHICLE'),property_try)&grepl(pattern=c('THEFT'),property_try)]
Burglary_type=property_try[grepl(pattern=c('BURGLARY'),property_try)]
Other_theft=property_try[!(grepl(pattern=c('VEHICLE'),property_try)&grepl(pattern=c('THEFT'),property_try)|grepl(pattern=c('BURGLARY'),property_try))]
```


```{r}
Moto_2010_2017=lapply(c(1:8),
    FUN=function(i){crime_2010_2017[[i]]%>%
    filter(crime_2010_2017[[i]]$CrimeCode_Description%in%Moto_theft_type)%>%
    group_by(CrimeCode_Description)%>%
    count()
})


Burglary_2010_2017=lapply(c(1:8),
    FUN=function(i){crime_2010_2017[[i]]%>%
    filter(crime_2010_2017[[i]]$CrimeCode_Description%in%Burglary_type)%>%
    group_by(CrimeCode_Description)%>%
    count()
})


Othertheft_2010_2017=lapply(c(1:8),
    FUN=function(i){crime_2010_2017[[i]]%>%
    filter(crime_2010_2017[[i]]$CrimeCode_Description%in%Other_theft)%>%
    group_by(CrimeCode_Description)%>%
    count()
})


Moto.num=sapply(c(1:8),FUN=function(i){sum(Moto_2010_2017[[i]]$n)})
Burglary.num=sapply(c(1:8),FUN=function(i){sum(Burglary_2010_2017[[i]]$n)})
Othertheft.num=sapply(c(1:8),FUN=function(i){sum(Othertheft_2010_2017[[i]]$n)})

propertycrime.df=data.frame(cbind(Y,Moto.num,Burglary.num,Othertheft.num))

```

```{r}
propertycrime.df%>%plot_ly(x = ~Y, y = ~Moto.num, type = 'scatter', mode = 'lines+markers',name='Motor vehicle theft')%>%
add_trace(y = ~Burglary.num, type = 'scatter', mode = 'lines+markers',name='Burglary')%>%
add_trace(y = ~Othertheft.num, type = 'scatter', mode = 'lines+markers',name='Othertheft')%>%
layout(title = "Property Crime changes", xaxis = xaxis, yaxis = yaxis,autosize = T,legend=list(x = 1, y = 0.6,font = list(size=10) ))
```

As shwon in the plot, for property crimes, burglary and othertheft contributes to the increase a lot after 2014, however, it might not be very influential to the increase between 2013~2014 of the total crimes since as shown Burglary even has some negative effect to the total crimes' increase between 2013 and 2014.



#Crime v.s Hour

Then, let's explore the hourly differences of the number of crimes.

```{r}
crime_2010_2017_hour=lapply(c(1:8),
    FUN=function(i){crime_2010_2017[[i]]%>%
    transmute(hour=crime_hour)%>%
    group_by(hour)%>%
    count()
})

crime_total=crime_final%>%filter(year!=2018)%>%
    transmute(hour=crime_hour)%>%
    group_by(hour)%>%
    count()



crime_hour_matrix=sapply(c(1:8),FUN=function(i){crime_2010_2017_hour[[i]]$n})



crimehour.df=data.frame(matrix(unlist(cbind(c(1:23),crime_hour_matrix,crime_total$n)),nrow=23,ncol=10))

colnames(crimehour.df)=c('hour','n1','n2','n3','n4','n5','n6','n7','n8','n9')


crimehour.df%>%plot_ly(x = ~hour, y = ~n1, type = 'scatter', mode = 'lines+markers',name='2010')%>%
add_trace(y = ~n2, type = 'scatter', mode = 'lines+markers',name='2011')%>%
add_trace(y = ~n3, type = 'scatter', mode = 'lines+markers',name='2012')%>%
add_trace(y = ~n4, type = 'scatter', mode = 'lines+markers',name='2013')%>%
add_trace(y = ~n5, type = 'scatter', mode = 'lines+markers',name='2014')%>%
add_trace(y = ~n6, type = 'scatter', mode = 'lines+markers',name='2015')%>%
add_trace(y = ~n7, type = 'scatter', mode = 'lines+markers',name='2016')%>%
add_trace(y = ~n8, type = 'scatter', mode = 'lines+markers',name='2017')%>%
layout(title = "hourly crime changes between 2010~2017", xaxis = xaxis, yaxis = yaxis,autosize = T,legend=list(x = 1, y = 0.6,font = list(size=10) ))

```

As shown,the distribution of number of crimes during a day doesn't change much between years.The beginning in

Besides,12 AM is the most crime-crowded hour during one day.






##Most Used Weapon Change


Let's see the top 5 crimes changes during 10AM~2PM during 2010~2017.

```{r}

crime_change=function(j,DF){
crime=lapply(c(10,11,12,13,14),FUN=function(i){DF%>%
filter(crime_hour==i)%>%
transmute(crime=CrimeCode_Description,crime_hour=crime_hour)%>%
filter(crime%in%top_5_crime)%>%
group_by(crime,crime_hour)%>%
count()%>%
arrange(desc(n))%>%data.frame()})

crime.df=rbind(crime[[1]],crime[[2]],crime[[3]],crime[[4]],crime[[5]])

crime.df%>%data.frame()%>%
plot_ly(x = ~unique(as.factor(crime_hour)), y = ~n[crime==unique(crime)[1]], marker = list(color = 'rgba(1,1,1, 0.0)'),name=paste(unique(crime.df$crime)[1]), type = 'scatter', mode = 'lines+markers')%>%
  
add_trace(y = ~n[crime==unique(crime)[2]],name = paste(unique(crime.df$crime)[2]),  type = 'scatter',mode = 'lines+markers')%>%
add_trace(y = ~n[crime==unique(crime)[3]],name = paste(unique(crime.df$crime)[3]),  type = 'scatter',mode = 'lines+markers')%>% 
add_trace(y = ~n[crime==unique(crime)[4]],name = paste(unique(crime.df$crime)[4]),  type = 'scatter',mode = 'lines+markers')%>% 
add_trace(y = ~n[crime==unique(crime)[5]],name = paste(unique(crime.df$crime)[5]),  type = 'scatter',mode = 'lines+markers')%>% 

layout(title = paste(j), xaxis = xaxis, yaxis = yaxis,autosize = T,legend=list(x = 1, y = 0.6,font = list(size=10) ))}


```

```{r}
crime_change(2010,crime_2010_2017[[1]])
crime_change(2011,crime_2010_2017[[2]])
crime_change(2012,crime_2010_2017[[3]])
crime_change(2013,crime_2010_2017[[4]])
crime_change(2014,crime_2010_2017[[5]])
crime_change(2015,crime_2010_2017[[6]])
crime_change(2016,crime_2010_2017[[7]])
crime_change(2017,crime_2010_2017[[8]])

```

As shown, for all years, the top5 crimes got huge increase at 12 AM,even though for every year the major increase might not be the same, however, theft plain seems to dominate the increase after 2010.

Thus, we can show the overall effect as follows.

```{r}
crime_ex2018=crime_final%>%filter(year!=2018)
crime_change('Total',crime_ex2018)
```
As shown, theft plain contributes the most to the crime increase at 12AM among all top 5 crimes, which is in accordance to the crime-vs-hour change per year shown previously.


#Crime Delayed Days

The time gap between the crime occurred date and the reported date contains quite a lot information which needed to be explore.Like what's the normal delayed time? What kind of crimes will have a long delayed time? These questions may be indicative to some social problem solutions which are very meaningful to further investigate.

```{r}

crime_10_17_delayed=lapply(c(1:8),
    FUN=function(i){crime_2010_2017[[i]]%>%
    transmute(Delayed_time=Delayed_time)%>%
    group_by(Delayed_time)%>%
    count()
})
  
crime_10_17_delayed_30=lapply(c(1:8),FUN=function(i){crime_10_17_delayed[[i]]$n[1:31]})


crime_10_17_delayed=data.frame(cbind(c(0:30),matrix(unlist(crime_10_17_delayed_30),nrow=31,ncol=8)))

names(crime_10_17_delayed)=c('delayed_days','n1','n2','n3','n4','n5','n6','n7','n8')


crime_10_17_delayed%>%plot_ly(x = ~delayed_days, y = ~n1, type = 'scatter', mode = 'lines+markers',name='2010')%>%
add_trace(y = ~n2, type = 'scatter', mode = 'lines+markers',name='2011')%>%
add_trace(y = ~n3, type = 'scatter', mode = 'lines+markers',name='2012')%>%
add_trace(y = ~n4, type = 'scatter', mode = 'lines+markers',name='2013')%>%
add_trace(y = ~n5, type = 'scatter', mode = 'lines+markers',name='2014')%>%
add_trace(y = ~n6, type = 'scatter', mode = 'lines+markers',name='2015')%>%
add_trace(y = ~n7, type = 'scatter', mode = 'lines+markers',name='2016')%>%
add_trace(y = ~n8, type = 'scatter', mode = 'lines+markers',name='2017')%>%
layout(title = "Delayed days (within 30) from 2010~2017", xaxis = xaxis, yaxis = yaxis,autosize = T,legend=list(x = 1, y = 0.6,font = list(size=10) ))
```

As shown, between years there are not much difference in the shape of the lines, showing that for most of the crime cases, people tend to report it right after it happened(within two days), after two days, the decrease switches to a much flatter manner,unlike the previous sharp one, may indicate more complicated crime cases which force the victim to delay the report date or special crime cases which make victims unwilling to report.

Interest may drawn by those crime cases which takes long time for the victims to report.


Then, let's see what kind of crime takes more 5 years to report based on the data from 2010~2017.

```{r}
library(wordcloud)
library(stringr)
library(tm)
crime_ex2018_cleaned=crime_ex2018[!(crime_ex2018$CrimeCode_Description==''|is.na(crime_ex2018$CrimeCode_Description)),]#exclude the rows with empty strings or missing values in crime code, since checked before, there are only less than 400 missing values here, thus the anaysis won't be influence much.
crime_ex2018_cleaned%>%
filter(Delayed_time>5*365)%>%
transmute(crime=CrimeCode_Description)->crimedelayed.df


documents <- Corpus(VectorSource(crimedelayed.df$crime))
documents = tm_map(documents, content_transformer(tolower))
documents = tm_map(documents, removePunctuation)
documents = tm_map(documents, removeWords, stopwords("english"))

words=documents[[1]]$content
for(i in 2:length(documents)){words=append(words,documents[[i]]$content)}
words_cleaned=noquote(words)




count_crime=rep(0, length(unique(words_cleaned)))
for(i in 1:length(unique(words_cleaned))){count_crime[i]=sum(words_cleaned==unique(words_cleaned)[i])}

countcrime.df=data.frame(cbind(unique(words_cleaned),count_crime))

countcrime.df$count_crime=as.numeric(as.character(countcrime.df$count_crime))

countcrime.df1=countcrime.df[order(countcrime.df$count_crime,decreasing = T),][1:10,]
countcrime.df1$V1=as.character(countcrime.df1$V1)

#paraphrase some terms to shorten them
countcrime.df1[2,1]='crm agnst chld'
countcrime.df1[6,1]='theft(over $950) without guns and life strikes'
countcrime.df1[7,1]='Sodomy'

names(countcrime.df1)=c('crime_kind','count_crime')



wordcloud(words = countcrime.df1$crime_kind, freq = countcrime.df1$count_crime,colors = brewer.pal(8,"Dark2"),
          min.freq = min(countcrime.df1$count_crime),random.color = T,   
          max.words = max(countcrime.df1$count_crime), random.order = T,  scale = c(4, 1),ordered.colors = F)  

```

As shown above, crimes take more than 5 years to report mainly includes two types, the first type takes long time for the victims to detect that they are involved in a crime,like document forgery, theft identity,these crimes are normally under great cover until revealed in a burst. Another type is mainly concerning with sex offense(rape,oral copulation,sodomy etc),and crime against children which takes courage for the victims to report by themselves.




#Crime Location


##Frequent Crime Location
```{r}
crime_final$Location=as.character(crime_final$Location)

sprintf('There are %i missing values in location',sum(is.na(crime_final$Location))+ sum(crime_final$Location=='')+sum(crime_final$Location=='(0, 0)'))# check the missing values in location
```

As shown there are 6872 missing values here, either is missing, recorded as (0,0) or empty string. However, compared with the big volume of crimes every year, this won't influence much to our analysis.


```{r}
library(leaflet)
crimelocation_cleaned1=crime_final[!(crime_final$Location==''),]
crimelocation_cleaned=crimelocation_cleaned1[!(crimelocation_cleaned1$Location=='(0, 0)'),]
rm(crimelocation_cleaned1)
#check the missing values in crime code description
sprintf('There are %i missing values in CrimeCode_Description', sum(is.na(crimelocation_cleaned$CrimeCode_Description))+ sum(crimelocation_cleaned$CrimeCode_Description==' '))
```

```{r}
long=rep(0,nrow(crimelocation_cleaned))
lat=rep(0,nrow(crimelocation_cleaned))
#subtract the longitude and latitude
for(i in 1:nrow(crimelocation_cleaned)){
U=unlist(strsplit(gsub("[(*)]", "",as.character(crimelocation_cleaned$Location[i])),','))
long[i]=as.numeric(U[2])
lat[i]=as.numeric(U[1])
}
crimelocation_cleaned%>%
  mutate(long=long,lat=lat)%>%
  group_by(Location,long,lat,Address)%>%
  count()%>%
  filter(n>1000)%>%
  data.frame()->crime_location.df



getColor <- function(crime) {
  sapply(crime$n, function(n) {
  if(n<= 1200) {
    "orange"
  } else {
    "red"
  } })
}


icons <- awesomeIcons(
  icon = 'ios-close',
  iconColor = 'black',
  library = 'ion',
  markerColor = getColor(crime_location.df)
)



leaflet(crime_location.df) %>% addTiles() %>%
  addAwesomeMarkers(~long, ~lat, popup = ~as.character(n), label = ~as.character(Address),icon=icons)

```

Here the extent of dangerous is measured by how many crimes happened in that location,here as shown in the map, the red icons stands for the most dangerous location while the orange one stands for less dangerous one. The label is the address name of that location.


##Crime Related To Rapes
```{r}
rape_words=factor(unique(words_cleaned[grep("\\<rape\\>", words_cleaned)]))
crimelocation_cleaned%>%
  mutate(long=long,lat=lat)%>%
  filter(CrimeCode_Description=='RAPE, FORCIBLE'|CrimeCode_Description=='RAPE, ATTEMPTED')%>%
  group_by(Location,long,lat,Address)%>%
  count()%>%filter(n>6)%>%data.frame()->rape_location.df



getColor <- function(crime) {
  sapply(crime$n, function(n) {
  if(n<10) {
    "orange"
  } else {
    "red"
  } })
}


icons <- awesomeIcons(
  icon = 'ios-close',
  iconColor = 'black',
  library = 'ion',
  markerColor = getColor(rape_location.df)
)



leaflet(rape_location.df) %>% addTiles() %>%
  addAwesomeMarkers(~long, ~lat, popup = ~as.character(n), label = ~as.character(Address),icon=icons)


```
As shown, the orange one stands for rape crime less than 10 but more than 6 times during 2010~2017 while the red one stands for more than 10 times rape or attemped rape during this period of time.From the map plot, it is eady to see that the central of Los Angeles,around Civic Center/Grand Park and WestLake/MacArthur Park, is the most crowded crime scences which need to draw attention. Besides, the rapes crimes are more centered around Hollywood with more frequent rape crimes.



##Crime Related To Children

```{r}
crime_children=unique(crime_ex2018$CrimeCode_Description[grepl(pattern=c("CHLD|CHILD"),crime_ex2018$CrimeCode_Description)])
crimelocation_cleaned%>%
  mutate(long=long,lat=lat)%>%
  filter(CrimeCode_Description%in%crime_children)%>%
  group_by(Location,long,lat,Address)%>%
  count()%>%filter(n>10)%>%data.frame()->childrencrime_location.df



getColor <- function(crime) {
  sapply(crime$n, function(n) {
  if(n<15) {
    "orange"
  } else {
    "red"
  } })
}


icons <- awesomeIcons(
  icon = 'ios-close',
  iconColor = 'black',
  library = 'ion',
  markerColor = getColor(childrencrime_location.df)
)


leaflet(childrencrime_location.df) %>% addTiles() %>%
  addAwesomeMarkers(~long, ~lat, popup = ~as.character(n), label = ~as.character(Address),icon=icons)


```

As shown, children crims has very obvious location cluster,showing that the center and the north side of Los Angeles are the most severe sites of children crimes,the south site also has one comparatively small cluster. The orange icon stands for more than 10 but less than 15 crimes happened in the same location, the red ones stand for those more than 15 times.




#Victim


##Victim Sex 


Firstly,let's see if there are some differences for victims of different sexs.

###Sex v.s.Crime Hour
```{r}
crime_final%>%filter(Victim_Sex=='F'|Victim_Sex=='M')%>%
transmute(crime_hour=crime_hour,Victim_Sex=Victim_Sex)%>%
arrange(desc(crime_hour))%>%group_by(Victim_Sex)%>%count(crime_hour)->c_sex_criminal
 
c_female=c_sex_criminal[c_sex_criminal$Victim_Sex=='F',2:3]
c_male=c_sex_criminal[c_sex_criminal$Victim_Sex=='M',2:3]

merge(c_male,c_female,by = 'crime_hour')%>%
mutate(n_total=n.x+n.y)%>%
plot_ly(x = ~crime_hour, y = ~n.x, marker = list(color = 'rgba(1,1,1, 0.0)'),name='male    Victims') %>%
add_trace(y = ~n.y, marker = list(color = 'rgba(55, 128, 191, 0.7)',
                                  line = list(color = 'rgba(55, 128, 191, 0.7)',
                                   width = 2)), type = 'bar',name='female Victims')%>%
add_trace(y = ~n.x, marker = list(color = 'rgba(219, 64, 82, 0.7)',
                                    line = list(color = 'rgba(219, 64, 82, 1.0)',
                                     width = 2)), type = 'bar')%>%
add_trace(y = ~n_total, name = 'total crimes', mode = 'lines+markers',type='scatter')%>%
layout(title = "Victim sex v.s. crime hour", xaxis = xaxis, yaxis = yaxis, margin = margin,autosize = FALSE,showlegend = T)  
```

As shown, 12 AM is the highest-crime hour during the day for both male and female. Unlike first impression,actually the males victims are outnumbering the female victims in most time of the day, especially at night.




### Sex vs Crime Year



```{r}
V_F=sapply(c(1:8),FUN=function(i){sum(crime_2010_2017[[i]]$Victim_Sex=='F')})
V_M=sapply(c(1:8),FUN=function(i){sum(crime_2010_2017[[i]]$Victim_Sex=='M')})

victim=data.frame(Y,V_M,V_F)
colnames(victim)=c('Year','Male','Female')

plot_ly(victim, x = ~Year, y = ~Male, name = 'male victims', type = 'scatter', mode = 'lines+markers') %>%
  add_trace(y = ~Female, name = 'female victims',  type = 'scatter',mode = 'lines+markers')

```
As shown, the change of numer of victims has no huge difference between males and females.In total,male victims outnumbered female victims and they both reaches their lowest point at 2013.However, as shown, the number of male victims seem to increase from 2016 while female ones are kind of stablized. 


###Sex v.s. Crime Type

Another interesting topic here would be if sex of victims will result in obvious distinctions of the number of some types of crimes.

####Rape

```{r}

F_Rape=sapply(c(1:8),FUN=function(i)
  {crime_2010_2017[[i]]%>%transmute(Victim_Sex=Victim_Sex,crime=CrimeCode_Description)%>%filter(Victim_Sex=='F')%>%filter(crime=='RAPE, FORCIBLE'|crime=='RAPE, ATTEMPTED')%>%count()})


M_Rape=sapply(c(1:8),FUN=function(i)
  {crime_2010_2017[[i]]%>%transmute(Victim_Sex=Victim_Sex,crime=CrimeCode_Description)%>%filter(Victim_Sex=='M')%>%filter(crime=='RAPE, FORCIBLE'|crime=='RAPE, ATTEMPTED'|crime=='SODOMY/SEXUAL CONTACT B/W PENIS OF ONE PERS TO ANUS OTH 0007=02')%>%count()})

Rape=data.frame(Y,cbind(as.numeric(M_Rape),as.numeric(F_Rape)))


colnames(Rape)=c('Year','Male','Female')

plot_ly(Rape, x = ~Year, y = ~Male, name = 'male victims', type = 'scatter', mode = 'lines+markers',name='male victims') %>%
  add_trace(y = ~Female, name = 'female victims',  type = 'scatter',mode = 'lines+markers')%>%
layout(title = "Victim sex in Rape Crimes", xaxis = xaxis, yaxis = yaxis, margin = margin,autosize = FALSE,showlegend = T)  

```

Here, as expected, the rape crime in females outnumbers the male victims' a lot even after including other expression of rape for man(since there are a lot types of sexual crimes listed here, some of them are quite general which has no distinguishment of male or female,not to mention the classfications for some cases might be problematic due to its complexity,like sexual acts between bloodtypes,rape or not rape?,thus this comparison might have some bias).Besides, from 2013 to 2015, there's a large increase in the number of the rape crimes towards females. After searching and combining different views, the increase in reports is the most possible cause of this increament, rather than an increase in incidents - fueled in part by student activism on university campuses. 


####Crime Against Children 

Crime against children has always been a severe and concerned issue in sociology, this section mainly discovers the total and sex-different trend of children crime among years.


```{r}
crime_children=unique(crime_ex2018$CrimeCode_Description[grepl(pattern=c("CHLD|CHILD"),crime_ex2018$CrimeCode_Description)])
F_children=sapply(c(1:8),FUN=function(i)
  {crime_2010_2017[[i]]%>%transmute(Victim_Sex=Victim_Sex,crime=CrimeCode_Description)%>%filter(Victim_Sex=='F')%>%filter(crime%in%crime_children)%>%count()})




M_children=sapply(c(1:8),FUN=function(i)
  {crime_2010_2017[[i]]%>%transmute(Victim_Sex=Victim_Sex,crime=CrimeCode_Description)%>%filter(Victim_Sex=='M')%>%filter(crime%in%crime_children)%>%count()})

Children=data.frame(Y,cbind(as.numeric(F_children),as.numeric(M_children)))


colnames(Children)=c('Year','Male','Female')

children=Children%>%mutate(total=Male+Female)

plot_ly(children, x = ~Year, y = ~Male, name = 'male victims', type = 'scatter', mode = 'lines+markers',name='male victims') %>%
  add_trace(y = ~Female, name = 'female victims',  type = 'scatter',mode = 'lines+markers')%>%
  add_trace(y = ~total, name = 'total victims',  type = 'scatter',mode = 'lines+markers')%>%
layout(title = "Victim sex in Children Crimes", xaxis = xaxis, yaxis = yaxis, margin = margin,autosize = FALSE,showlegend = T)  

```

As shown, the crimes against male children outnumber female children a lot among all years, however, clearly trend of decrease is shown as pleasant signal of crime controlling from LAPD for both male and female children. 





##Victim Age

Next, we will discover the differences in the number of crimes among different victims age.


First check the missing values of the Victim age  to ensure we don't have too much bias among years.

```{r}
incomplete_crime=sapply(c(1:8),FUN=function(i){sum(is.na(crime_2010_2017[[i]]$Victim_Age ))})
data.frame(cbind(Y,unlist(incomplete_crime)))->incomplete.df
names(incomplete.df)=c('year','number')
plot_ly(incomplete.df,x=~factor(year),y=~number,type='scatter',mode='lines+markers')%>%layout(title = 'missing crime info of victim ages among years', xaxis = xaxis, yaxis = yaxis, margin = margin,autosize = FALSE,showlegend = F,legend = list(x = 0.9, y = 0.5))

```

Here, as shown, between 2010 to 2011, there's a large drop of the missing values,besides,due to the steady flow after 2011, what happened in 2010 become suspicious. There are no official explannation of missing values but here we can gain some insights of it with comparison of the crime types of the missed cases of 2010 with that of 2012(here 2012 is picked as an example which is in the steady trend bwtween 2011 to 2014 but is not too far a way from 2010)

During analysis, very interesting stuff is found out that in 2010 in victim age missing cases,vehicle-stolen toppest the others a lot,about 16587, however, after 2010, the number of this crime drop down immensely to 5 in 2012,there's no official explanations of this weird drop, as checked, I found a very strange pattern ,for year (2012+i), the Victim age for VEHICLE-STOLEN equal to (11+i) will taking 99% of the total VEHICLE-STOLEN cases,since there are still cases with victim's age are not the 'conventional' ones, I think it might the possible pattern to refill the missing values here, this dataset is from the official website, I cross check with some of the sources,same pattern is found.


```{r}
top_missing_crime_2010=crime_2010_2017[[1]]%>%
  filter(is.na(crime_2010_2017[[1]]$Victim_Age))%>%
  group_by(CrimeCode_Description)%>%
  count()%>%
  arrange(desc(n))%>%
  head(3)
top_missing_crime_2010%>%knitr::kable()
```


```{r}
sprintf('The top crime with the most missing values in Victim \'s Age missing in 2010 is %s which %i of missing cases',top_missing_crime_2010$CrimeCode_Description[1],top_missing_crime_2010$n[1])
```



```{r}
top_missing_crime_2012=crime_2010_2017[[3]]%>%
  filter(is.na(crime_2010_2017[[3]]$Victim_Age))%>%
  group_by(CrimeCode_Description)%>%
  filter(CrimeCode_Description=='VEHICLE - STOLEN')%>%
  count()


sprintf('The VEHICLE - STOLEN with missing values in Victim \'s Age in 2012 has %i of  cases',top_missing_crime_2012$n[1])

```


Then, after analyzing the missing values, we will discuss the victim's ages,here, for more unbised result(only for the distribution with age), we won't use the data from 2010 for analysis, also here crimes are checked for victim's aging between 20~40 which is the interested part here, there is no very obvious pattern of refillment of the missing values here.


```{r}
crime_ex20182010=crime_ex2018%>%filter(year!=2010)
crime_ex20182010%>%group_by(Victim_Age)%>%count()%>%data.frame()->crime_age
plot_ly(crime_age,x = ~Victim_Age,y = ~ as.numeric(n),type='scatter',mode='lines+markers')%>%
layout(title = 'Age vs number of Crimes from 2011~2017',xaxis = list(title='Victim Age'), yaxis =list(title='Number of Crimes'), margin = margin,autosize = FALSE,showlegend = F,legend = list(x = 0.9, y = 0.5))

```

As shown, age between 20~30 is the peak of the distribution(ignoring the problematic peak between 12~16), suggesting higher inclination of crime suffering of people ranging from this age interval.

Then, let's detaily analyze the types of crimes these people are suffered of.

```{r}
crime_ex20182010%>%
  filter(Victim_Age<=30&Victim_Age>=20)%>%
  group_by(CrimeCode_Description)%>%
  count()%>%
  arrange(desc(n))%>%
  head(5)%>%
  data.frame()->crime_20_30

crime_20_30%>%knitr::kable()


```

As shown Battery-simple assault, burglary from vehicle, intimate partner-simple assault, assault with deadly weapon, aggravated assault and burglary are the top 5 crimes suffered by victims aging from 20~30 where the first 3 crimes top the latter ones a lot. These crime show only moderate severity.

Then,let's discover the dangerous spot for victims aged from 20~30
```{r}
crime_20_30=factor(crime_20_30$CrimeCode_Description)

crimelocation_cleaned%>%
  mutate(long=long,lat=lat)%>%
  filter(CrimeCode_Description%in%crime_20_30)%>%
  group_by(Location,long,lat,Address)%>%
  count()%>%filter(n>200)%>%data.frame()->crime_20_30_location.df



getColor <- function(crime) {
  sapply(crime$n, function(n) {
  if(n<400) {
    "orange"
  } else {
    "red"
  } })
}


icons <- awesomeIcons(
  icon = 'ios-close',
  iconColor = 'black',
  library = 'ion',
  markerColor = getColor(crime_20_30_location.df)
)



leaflet(crime_20_30_location.df) %>% addTiles() %>%
  addAwesomeMarkers(~long, ~lat, popup = ~as.character(n), label = ~as.character(Address),icon=icons)

```
As shown in the map plot, central Los Angeles to the NorthWestern part of this city forms a line of hot spot of crimes aiming at victims from 20 to 30. The orange icon here stands for the number of crimes at the same location ranges from 25 to 50 per year, the red icon stands for those more than 50 cases.


Evidence of possible pattern for missing value refill.

```{r}
p_victimage=lapply(c(1:6),FUN=function(i){crime_2010_2017[[(i+2)]]%>%filter(CrimeCode_Description=='VEHICLE - STOLEN')%>%filter(Victim_Age==(i+10))%>%count()/crime_2010_2017[[i+2]]%>%filter(CrimeCode_Description=='VEHICLE - STOLEN')%>%count()})

sprintf('The percentage of victims of VEHICLE-STOLEN for 2012 which is equal to 11 takes up the total amount of the  VEHICLE-STOLEN crime is %f',p_victimage[[1]])
sprintf('The percentage of victims of VEHICLE-STOLEN for 2013 which is equal to 12 takes up the total amount of the  VEHICLE-STOLEN crime is %f',p_victimage[[2]])
sprintf('The percentage of victims of VEHICLE-STOLEN for 2014 which is equal to 13 takes up the total amount of the  VEHICLE-STOLEN crime is %f',p_victimage[[3]])
sprintf('The percentage of victims of VEHICLE-STOLEN for 2015 which is equal to 14 takes up the total amount of the  VEHICLE-STOLEN crime is %f',p_victimage[[4]])
sprintf('The percentage of victims of VEHICLE-STOLEN for 2016 which is equal to 15 takes up the total amount of the  VEHICLE-STOLEN crime is %f',p_victimage[[5]])
sprintf('The percentage of victims of VEHICLE-STOLEN for 2017 which is equal to 16 takes up the total amount of the  VEHICLE-STOLEN crime is %f',p_victimage[[6]])
```









##Victim Descent

Then, the next topic lies in the exploration of the victims' descent. What's the composition of the nationality of the victims' descent? 


Firstly, let's check the missing values in the victim descnt part

```{r}
incomplete_crime=sapply(c(1:8),FUN=function(i){sum(crime_2010_2017[[i]]$Victim_Descent==''|is.na(crime_2010_2017[[i]]$Victim_Descent))})
data.frame(cbind(Y,unlist(incomplete_crime)))->incomplete.df
names(incomplete.df)=c('year','number')
plot_ly(incomplete.df,x=~factor(year),y=~number,type='scatter',mode='lines+markers')%>%layout(title = 'missing crime info of victim descent among years', xaxis = xaxis, yaxis = yaxis, margin = margin,autosize = FALSE,showlegend = F,legend = list(x = 0.9, y = 0.5))
```


Here the missing value is ranging from 16k~23K, taking around 10% of the total records. The highest range of the missing value number among years is about 7k,taking 5% of the total records. For more accuracy, the analysis will only based on 2011~2014's data which has comparatively lower number of missing values.



```{r}
crime_20112014=crime_ex20182010%>%filter(year>=2011&year<2015)%>%filter(Victim_Descent!='')%>%filter(Victim_Descent!='-')%>%group_by(Victim_Descent)%>%count()%>%arrange(desc(n))%>%data.frame()

crime_20112014$Victim_Descent=c('Hispanic/Latin/Mexican','White','Black','Other','Other Asian','Unknown','Korean','Filipino','American Indian/Alaskan Native','Chinese','Pacific Islander','Japanese','Hawaiian','Vietnamese','Guamanian','Asian Indian','Cambodian','Samoan','Laotian')

plot_ly(crime_20112014, labels = ~Victim_Descent, values = ~n, type = 'pie')%>%layout(title = 'Victim descent composition',margin = margin,autosize = T,showlegend = T)

```


As shown, for the absolute number of Victims descent, the top three lies in Hispanic/Latin/Mexican, White and Black with Hispanic/Latin/Mexican takes the highest percentage of 38.3%.
It seems that there are some differences here between different nationality, however, the total population composition of Los Angeles might be introduced to gain a more proper conclusion. Here, the population raw data are from the 2010 ans 2016 census, average are taken to show the general composition of different races. The data is trimed and only keep the interested ones.


```{r}

population_comp=readxl::read_xlsx('/Users/tanzhenyu/Desktop/Stat847/Cirme_Project/population composition.xlsx')
population_comp=population_comp%>%mutate(avg=rowMeans(population_comp[,2:3]))
crime_number=crime_20112014[c(2,3,1),2]

v=rep(0,3)
for(i in 1:3){
  v[i]=c(as.vector(unlist(crime_number))[i]/(5*population_comp[3,4]))
}

population_comp[-4,]%>%mutate(cond=unlist(v))%>%transmute(race=Race,invloved_prob=cond)%>%arrange(desc(invloved_prob))%>%knitr::kable()

```

Here as shown, the order of the conditional probablity of the  after considering the total population is still
the same, the involved probability is around 0.01 of the total population per year for the top two races which are Hispanic or Latino and White alone whereas Black or African American alone takes only around half of 0.01.



#Criminal 

Let's see the activities associated with the suspect in commission of the crime.Here another description dataset is used.

```{r}

suspect=read.csv('/Users/tanzhenyu/Desktop/Stat847/suspect.csv',header=F)

code=sapply(c(1:nrow(suspect)),FUN=function(i){substr(suspect[i,],1,4)})
description=sapply(c(1:nrow(suspect)),FUN=function(i){str_trim(substring(suspect[i,],5))})
code_description=cbind(code,description)%>%data.frame()

```


Firstly,as usual,check the missing values.

```{r}
incomplete_crime=sapply(c(1:8),FUN=function(i){sum(crime_2010_2017[[i]]$MO_Codes==''|is.na(crime_2010_2017[[i]]$MO_Codes))})
data.frame(cbind(Y,unlist(incomplete_crime)))->incomplete.df
names(incomplete.df)=c('year','number')
plot_ly(incomplete.df,x=~factor(year),y=~number,type='scatter',mode='lines+markers')%>%layout(title = 'missing crime info of Mo code among years', xaxis = xaxis, yaxis = yaxis, margin = margin,autosize = FALSE,showlegend = F,legend = list(x = 0.9, y = 0.5))
```
Here, as shown, the missing value of MO code has similar pattern as Victim Descent, thus here 2011 to 2014's data will be used.


##Rape Criminal Activities

As analyzed before, for rape crimes, almost all the victims are females,thus it will be very meaningful to see what kind of activities are the criminals associated, this will gain some ideas for women's self defense when facing similar situations.


```{r}

crime_2011_2014_female=crime_ex20182010%>%filter(year>=2011&year<2015)%>%filter(MO_Codes!='')%>%filter(Victim_Sex=='F')%>%filter(CrimeCode_Description=='RAPE, FORCIBLE'|CrimeCode_Description=='RAPE, ATTEMPTED')


code=sapply(c(1:nrow(crime_2011_2014_female)),FUN=function(i){unlist(strsplit(as.character(crime_2011_2014_female$MO_Codes[i])," "))})


code1=unlist(code)

code2=code1[-which(code1=='2021'|code1=='2024')]#remove two codes which are not included in the official description file



MO_description=rep(0,length(code2))
for(i in 1:length(code2))
{ MO_description[i]=as.character(code_description$description[code_description$code==code2[i]])}


MO_description_df=data.frame(MO_description)
colnames(MO_description_df)='description'




MO_description_df%>%group_by(description)%>%count()%>%arrange(desc(n))%>%head(10)%>%
plot_ly(labels = ~description, values = ~n, type = 'pie')%>%layout(title = 'Associate activities of Rape towards women',margin = margin,autosize = T,showlegend = T) 
  

```

The top 10 activities are shown in the pie plot, actual intercourse takes the top as expected,there are some almost deterministic acts in the rape crimes,the meaningful information here goes to things like victim knew suspect,the rape goes under influence of drugs/liquor,acquaintance, these three activities show warnings to the females that be careful of those people you just meet or know for some time,don't think you know them well,do not use drugs or liquor under no safe cover(drugs are not that good as well).




##Children Criminal Activities

Another analysis will go to another focused group, the children, what aspects should we pay attention to prevent the crime from happening?


```{r}

crime_2011_2014_children=crime_ex20182010%>%filter(year>=2011&year<2015)%>%filter(MO_Codes!='')%>%filter(CrimeCode_Description%in%crime_children)


code=sapply(c(1:nrow(crime_2011_2014_children)),FUN=function(i){unlist(strsplit(as.character(crime_2011_2014_children$MO_Codes[i])," "))})


code1=unlist(code)


code2=code1[-which(code1=='2021'|code1=='2024'|code1=='2034'|code1=='2151'|code1=='2200'|code1=='4017')]#remove codes which are not included in the official description file


MO_description=rep(0,length(code2))
for(i in 1:length(code2))
{ MO_description[i]=as.character(code_description$description[code_description$code==code2[i]])}


MO_description_df=data.frame(MO_description)
colnames(MO_description_df)='description'


MO_description_df%>%group_by(description)%>%count()%>%arrange(desc(n))%>%filter(
description!='Victim is 6 years old thru 13 years old'&description!='Victim is 14 years old thru 17 years old'&description!='Victim is Newborn-5 years old')%>%#filtering the age issue as we have discussed it before
head(10)%>%
plot_ly(labels = ~description, values = ~n, type = 'pie')%>%layout(title = 'Associate activities of Children Crimes',margin = margin,autosize = T,showlegend = T,list(font =list(size=1))) 
  

```

Similar as what have shown in rape crimes, this pie plot present general idea of what kind of activities are involved in the children's crimes by the criminal(here are the top 10 activities).The meaningful information here is that firstly,the children's parents and other family members take high order of the activities asscoiated,indicating family issue takes noticeble proportion of children's crimes.Besides,from shown,crime against children includes tounches which is non-severe acts but should not be ignored since the criminals might be more aggresive after these minor acts.


#Comparison With Crimes In Vancouver

For this section, the analysis will lie into the comparison of Vancouver, also as a very important and popular city, with Los Angeles. The main scope will be drawn to the conditional crime rate(considering the population) from 2010 to 2016(data of 2017 is incomplete for Vancouver case).Since the census in Canada and American are not in yearly bases, thus here the missing values between two censuses will be interpolated.

```{r}
crime_vancouver=read.csv('/Users/tanzhenyu/Desktop/Stat847/crime.csv',header=T)

popualtion_vancouver=read.csv('/Users/tanzhenyu/Desktop/Stat847/CensusProfile2016-ProfilRecensement2016-20180424034413.csv')

y_popu=as.numeric(as.character(popualtion_vancouver[2:3,4]))
x_popu=c(2011,2016)
x_out=c(2010,2011,2012,2013,2014,2015,2016)

y_popu1=as.numeric(population_comp[4,2:3])
x_popu1=c(2010,2016)
x_out1=c(2010,2011,2012,2013,2014,2015,2016)



Van_2010_2016_popu=approx(x_popu,y_popu,x_out,method='linear',rule=2)
Los_2010_2016_popu=approx(x_popu1,y_popu1,x_out1,method='linear',rule=2)


c1=crime_vancouver%>%filter(YEAR>=2010&YEAR<2017)%>%group_by(YEAR)%>%count()
crime_prob_van=cbind(c1,Van_2010_2016_popu)%>%data.frame()%>%transmute(Year=YEAR,conditionvan=n/y)
crime_prob_los=cbind(Victim.df%>%filter(Y!=2017),Los_2010_2016_popu)%>%data.frame()%>%transmute(Y=Y,conditionlos=V_num/y)

crime_conditional=cbind(crime_prob_los,crime_prob_van)%>%transmute(year=Y,condition_van=conditionvan,condition_los=conditionlos)%>%data.frame()

plot_ly(crime_conditional, x = ~year, y = ~condition_van, name = 'Vancouver', type = 'scatter', mode = 'lines+markers') %>%
  add_trace(y = ~condition_los, name = 'Los Angeles',  type = 'scatter',mode = 'lines+markers')%>%
layout(title = "Conditional Crime Rate of Los Angeles and Vancouver", xaxis = xaxis, yaxis = yaxis, margin = margin,autosize = FALSE,showlegend = T)  


```

As shown, for Vancouver, the conditional crime rate is increasing these years, suggesting high demand of crime control in these area,on the other hand for Los Angeles, the conditional crime rate is staying in a comparatively stable level with some increase trend at the end of 2016. 

Here, the outcome might have some bias for the fact that one person might commit several crimes per year, since here we couldn't know which crime is commited by the same person so unfortunately this is the best we could do, that's why here I didn't use the term 'crime rate per person',but suggesting the trend instead.


#Conclusions

For this project, the analysis has been divided into several parts,namely Crime Overview, Victim Sex, Victim Age, Victim Descent and Comparison with crimes in Vancouver.The analysis has drawn insights in each of the parts,some general understandings could be gained like, after 2013, the LAPD has tighten its recording procedure which shows greater absolute numnber of crimes, the top crimes in los angeles includes simple assault, burglary from vehicle and theft, 12 AM is the highest crime time in Los Angeles, central Los Angeles is the most crime-crowded places, so on so forth. Further studies are very possible since there are a lot of information are covered against the public, and some information might have been modified for privacy issue or missing values.Besides, here the understandings presented are just the first step towards the crime dataset, it might connect to criminology if go further.
























